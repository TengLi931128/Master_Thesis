{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is a practice about how to use Word2Vec as a Embedding layer.\\nTeng Li\\n30.09.2021\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a practice about how to use Word2Vec as a Embedding layer.\n",
    "Teng Li\n",
    "30.09.2021\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6253,  1.0858, -0.7127]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First of all Let's try to build a Embedding layer.\n",
    "'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "word_to_ix = {\"Li\": 0, \"Teng\": 1} # init a dictionary\n",
    "embeds = nn.Embedding(2, 3)  # 2 words in vocab, 3 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"Li\"]], dtype=torch.long)\n",
    "Li_embed = embeds(lookup_tensor)\n",
    "print(Li_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6253,  1.0858, -0.7127],\n",
      "        [-0.1916,  0.6963, -1.6411]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# we can see the weights of Embedding layers\n",
    "print(embeds.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1000, 2.8000, 8.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Now Let's try to init our Embedding layer with a known weights\n",
    "w = torch.FloatTensor([[1.1, 2.8, 8],\n",
    "                       [3, 4, 5]])\n",
    "embeds = nn.Embedding.from_pretrained(w)\n",
    "Li_embed = embeds(lookup_tensor)\n",
    "print(Li_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now let's get the weights from trained model(word2vec here)\n",
    "# first of all we need to download word2vec\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# then we can load word2vec\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/home/teng/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz',\n",
    "                                                        binary=True,limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# we can also lookup a vector of word\n",
    "love_vec = model['love']\n",
    "print(love_vec.shape)\n",
    "#print(love_vec)\n",
    "# lets see which words are most similar to 'love'\n",
    "#love_similar = model.most_similar(['love'],topn=5)\n",
    "#print(love_similar)\n",
    "# which words are similar to 'king'-'man'+'woman'?\n",
    "#print(model.most_similar(positive=['king','woman'],negative=['man'],topn=5))\n",
    "# and 'student' - 'book'\n",
    "#print(model.most_similar(negative=['student','book'],topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy', 'fall', 'in', 'love', 'with', 'girl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'boy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-314430dd7f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mwords_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words_id:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# and the words_vec are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'boy'"
     ]
    }
   ],
   "source": [
    "# the weights of Embedding layer are\n",
    "W2V_weights = torch.FloatTensor(model.vectors)\n",
    "# so the our Embedding layer could be\n",
    "embeds = nn.Embedding.from_pretrained(W2V_weights)\n",
    "# the vocab(word >index) is \n",
    "Vocab = model.wv.vocab\n",
    "# e.g the words are \n",
    "t = 'boy fall in love with girl'\n",
    "words = t.split()\n",
    "print(words)\n",
    "# the index of words can be found by\n",
    "L = len(words)\n",
    "words_id = torch.LongTensor(L)\n",
    "for l in range(L):\n",
    "    word = words[l]\n",
    "    words_id[l] = torch.tensor(Vocab[word].index)\n",
    "print('words_id:',words_id)\n",
    "# and the words_vec are\n",
    "words_vec = embeds(words_id)\n",
    "print(words_vec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(count:913, index:87)\n",
      "like\n"
     ]
    }
   ],
   "source": [
    "print(Vocab['like'])\n",
    "#print(type(Vocab))\n",
    "# now try to use index to find word\n",
    "Vocab_list = list(Vocab.keys())\n",
    "print(Vocab_list[87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But we can find that some words are not in this Vocab\n",
    "\"'s\" not in Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word not in vocab:25.00%\n",
      "{'a'}\n"
     ]
    }
   ],
   "source": [
    "# let's check which words not in vocab\n",
    "def check_word(data,vocab):\n",
    "    oov = set()\n",
    "    oov_num = 0\n",
    "    sum_num = len(data)\n",
    "    for word in data:\n",
    "        if word not in vocab:\n",
    "            oov.add(word)\n",
    "            oov_num += 1\n",
    "    print('word not in vocab:{:.2%}'.format(oov_num/sum_num))\n",
    "    print(oov)\n",
    "# e.g the sentence\n",
    "t = 'a boy fall in love with a girl'\n",
    "s = t.split()\n",
    "check_word(s,Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(count:1, index:10000)\n",
      "Vocab(count:8444, index:1556)\n"
     ]
    }
   ],
   "source": [
    "#so we need to clean this dataset\n",
    "#we will remove all the punctuation and embedd all the unknow words with zero vector. \n",
    "#first add 'unk' to our model\n",
    "model['unk'] = np.zeros(300,dtype=np.float32)\n",
    "#print(model['unk'])\n",
    "print(Vocab['unk'])\n",
    "print(Vocab['boy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'&' in Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def word2index(docs,vocab):\n",
    "    for i,doc in enumerate(docs):\n",
    "        L = len(doc)\n",
    "        words_id = torch.LongTensor(L)\n",
    "        for l in range(L):\n",
    "            word = doc[l]\n",
    "            words_id[l] = torch.tensor(vocab[word].index)\n",
    "        print(words_id)\n",
    "        docs[i] = words_id\n",
    "    return docs\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['boy','love','girl']\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2index(doc):\n",
    "    L = len(words)\n",
    "    words_id = torch.LongTensor(L)\n",
    "    for l in range(L):\n",
    "        word = words[l]\n",
    "        words_id[l] = torch.tensor(Vocab[word].index)\n",
    "    print('words_id:',words_id)\n",
    "    return words_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_id: tensor([1556,  707,    1,  746,    8, 1408])\n",
      "tensor([1556,  707,    1,  746,    8, 1408])\n"
     ]
    }
   ],
   "source": [
    "print(word2index(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1556,  746, 1408])\n",
      "tensor([6147,    8, 1556])\n",
      "tensor([ 28,   4,  11, 889])\n"
     ]
    }
   ],
   "source": [
    "a = word2index(d,Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1556,  746, 1408]), tensor([6147,    8, 1556])]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
