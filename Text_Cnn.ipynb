{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is a CNN which is used in sentiment classification, idea of Kim's CNN.\\nTeng Li\\n21.09.2021\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a CNN which is used in sentiment classification, idea of Kim's CNN.\n",
    "Teng Li\n",
    "21.09.2021\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-9c2bf544aaa9>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9c2bf544aaa9>\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    with torch.no\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import gensim\n",
    "# then we can load word2vec\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/home/teng/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz',\n",
    "                                                        binary=True,limit=10000)\n",
    "#first add 'unk' to our model\n",
    "model['unk'] = np.zeros(300,dtype=np.float32)\n",
    "# the weights of Embedding layer are\n",
    "W2V_weights = torch.FloatTensor(model.vectors)\n",
    "# the vocab of this Embedding is\n",
    "Vocab = model.wv.vocab\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "WORD_VECTOR_SIZE = 300 # The size of word vector\n",
    "FILTER_SIZE = [3,4,5] # 3 different size of filter\n",
    "FILTER_NUM = [100,100,100] # The number of each size filter\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):# inherit from nn.Module\n",
    "    \n",
    "    def __init__(self):#init the module\n",
    "        super().__init__()\n",
    "        #Embedding layer\n",
    "        self.embed = nn.Embedding.from_pretrained(W2V_weights)\n",
    "        #Conv layers\n",
    "        self.conv1 = nn.Conv2d(1,FILTER_NUM[0],(FILTER_SIZE[0],WORD_VECTOR_SIZE))\n",
    "        self.conv2 = nn.Conv2d(1,FILTER_NUM[1],(FILTER_SIZE[1],WORD_VECTOR_SIZE))\n",
    "        self.conv3 = nn.Conv2d(1,FILTER_NUM[2],(FILTER_SIZE[2],WORD_VECTOR_SIZE))\n",
    "        #Fc layer\n",
    "        self.fc1 = nn.Linear(3*100, 80) #input 20*10*10, out 500\n",
    "        self.fc2 = nn.Linear(80, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):#forward propagation\n",
    "        #Embedding layer\n",
    "        x = self.embed(x)   # batch*1*N(word_num in doc) -> batch*1*N*WORD_VECTOR_SIZE \n",
    "        print(x.shape)\n",
    "        #Conv layers\n",
    "        out1 = self.conv1(x) # batch*1*N*WORD_VECTOR_SIZE -> batch*100*N*WORD_VECTOR_SIZE\n",
    "        out2 = self.conv2(x)\n",
    "        out3 = self.conv3(x)\n",
    "        out1 = torch.tanh(out1)\n",
    "        out2 = torch.tanh(out2)\n",
    "        out3 = torch.tanh(out3)\n",
    "        \n",
    "        #Max over time pooling layer\n",
    "        max1,_ = torch.max(out1,2)\n",
    "        max2,_ = torch.max(out2,2)\n",
    "        max3,_ = torch.max(out3,2)\n",
    "        #print(max1.size())\n",
    "        \n",
    "        #Concatenates the features and reshape for FC layer\n",
    "        Max = torch.cat((max1,max2,max3),1)\n",
    "        #print(Max.size())\n",
    "        Max = Max.view(BATCH_SIZE,-1)\n",
    "        #print(Max.size())\n",
    "        \n",
    "        #Fc layer\n",
    "        Out = self.fc1(Max) # batch*300 -> batch*80\n",
    "        Out = torch.tanh(Out)\n",
    "        Out = self.fc2(Out) # batch*80 -> batch*20\n",
    "        Out = torch.tanh(Out)\n",
    "        Out = self.fc3(Out) # batch*20 -> batch*2\n",
    "        Out = f.log_softmax(Out,dim=1) #\"dim=1\" means logsoftmax along 2 sentiment(pos or neg)\n",
    "\n",
    "        return Out\n",
    "\n",
    "    def predict(self,x):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x)\n",
    "            _,y_hat = torch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 16,  45,  32, 180, 186, 127,   0,   0,  16,  45,  32, 180, 186, 127,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,  32,  33, 223, 201,  61,  86,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,  24, 211, 223, 201,  61,  86,\n",
      "            0,   0,  32, 211, 223, 201,  61,  86,   0,   0,  64, 211, 223, 201,\n",
      "           61,  86,   0,   0, 100,   0,   0,   0,   0,   0,   0,   0,  44,   1,\n",
      "            0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,   0,  44,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           88, 211, 223, 201,  61,  86,   0,   0,  96, 211, 223, 201,  61,  86,\n",
      "            0,   0, 128, 211, 223, 201,  61,  86,   0,   0,   1,   0,   0,   0,\n",
      "            0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0]]])\n"
     ]
    }
   ],
   "source": [
    "# N is the number of word in doc\n",
    "N = 100\n",
    "data = torch.ByteTensor(BATCH_SIZE,1,N)\n",
    "data = data.long()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "data = torch.LongTensor([[[1,2,3,6,88,32]],\n",
    "                     [[4,6,3,6,8,21]]])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 100, 300])\n",
      "tensor([[-0.7831, -0.6106],\n",
      "        [-0.7824, -0.6112]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "Text_CNN = ConvNet().to(DEVICE)\n",
    "Out = Text_CNN(data)\n",
    "print(Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
