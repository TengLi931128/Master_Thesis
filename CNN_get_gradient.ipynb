{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7911, 0.8758, 0.1104, 0.1205],\n",
      "          [0.8092, 0.5409, 0.6832, 0.2473],\n",
      "          [0.4817, 0.0541, 0.2431, 0.5817],\n",
      "          [0.2159, 0.9328, 0.3239, 0.4082]]]], requires_grad=True)\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "here I try to get the gradient of a cnn\n",
    "Teng Li\n",
    "24.11.2021\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "# input\n",
    "x = torch.rand([1,1,4,4])\n",
    "x.requires_grad_()\n",
    "print(x)\n",
    "# target\n",
    "y = torch.tensor([0])\n",
    "print(y)\n",
    "#loss function\n",
    "loss_func = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv layers\n",
    "conv1 = nn.Conv2d(1,3,(2,4)) #(1,1,4,4)->(1,3,3,1)\n",
    "#fc layers\n",
    "fc1 = nn.Linear(9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conv: tensor([[[[ 0.0072],\n",
      "          [ 0.3788],\n",
      "          [ 0.2685]],\n",
      "\n",
      "         [[ 0.1580],\n",
      "          [ 0.1107],\n",
      "          [ 0.0498]],\n",
      "\n",
      "         [[-0.1238],\n",
      "          [ 0.3206],\n",
      "          [ 0.2333]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "after reshape: tensor([[ 0.0072,  0.3788,  0.2685,  0.1580,  0.1107,  0.0498, -0.1238,  0.3206,\n",
      "          0.2333]], grad_fn=<ViewBackward>)\n",
      "after fc: tensor([[ 0.1423, -0.4534]], grad_fn=<AddmmBackward>)\n",
      "y_hat: tensor([[-0.4390, -1.0347]], grad_fn=<LogSoftmaxBackward>)\n",
      "loss: tensor(0.4390, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = conv1(x)\n",
    "print('after conv:',out)\n",
    "print(out.req)\n",
    "out = out.view(1,-1)\n",
    "print('after reshape:',out)\n",
    "out = fc1(out)\n",
    "print('after fc:',out)\n",
    "y_hat = f.log_softmax(out,dim=1)\n",
    "print('y_hat:',y_hat)\n",
    "loss = loss_func(y_hat,y)\n",
    "print('loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[-0.0247,  0.0290, -0.0290, -0.0380],\n",
      "          [ 0.0051,  0.1221, -0.1030,  0.0166],\n",
      "          [ 0.0200,  0.0196,  0.0317, -0.0091],\n",
      "          [-0.0979, -0.0485,  0.0700, -0.0687]]]]),)\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.autograd.grad(loss,x)\n",
    "print(gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
